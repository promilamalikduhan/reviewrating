{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841b968b",
   "metadata": {},
   "source": [
    "You have to scrape at least 20000 rows of data. You can scrape more data as well, it’s up to you. more the data better the model\n",
    "In this section you need to scrape the reviews of different laptops, Phones, Headphones, smart watches, Professional Cameras, Printers, Monitors, Home theater, Router from different e- commerce websites.\n",
    "Basically, we need these columns-\n",
    "1) reviews of the product.\n",
    "2) rating of the product.\n",
    "You can fetch other data as well, if you think data can be useful or can help in the project. It completely depends on your imagination or assumption.\n",
    "Hint:\n",
    "• Try to fetch data from different websites. If data is from different websites, it will help our model to remove the effect of over fitting.\n",
    "• Try to fetch an equal number of reviews for each rating, for example if you are fetching 10000 reviews then all ratings 1,2,3,4,5 should be 2000. It will balance our data set.\n",
    "• Convert all the ratings to their round number, as there are only 5 options for rating i.e., 1,2,3,4,5. If a rating is 4.5 convert it 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc527cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen  \n",
    "from urllib.request import Request  \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import Image, HTML\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException,TimeoutException,WebDriverException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import urllib.parse\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bf2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e89f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siteinfo={\"Amazon\":\"http://www.amazon.in\",\"Flipkart\":\"http://www.flipkart.com\"}\n",
    "#product_info={1:'SmartPhone',2:'Laptop',3:'Headphone',4:'smart watch',5:'Professional Camera',6:'Printer',7:'Home theater',8:'Router'}\n",
    "\n",
    "\n",
    "siteinfo={\"Amazon\":\"https://www.amazon.in\"}\n",
    "for websitename,siteurl in siteinfo.items(): \n",
    "    product_info={1:'SmartPhone',2:'Laptop',3:'Headphone',4:'smart watch',5:'Professional Camera',6:'Printer',7:'Home theater',8:'Router'}\n",
    "    for itemKey,itemValue in product_info.items():\n",
    "        driver.get(siteurl)\n",
    "        time.sleep(2)\n",
    "        secs=20\n",
    "        search_field_designation=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.ID,'twotabsearchtextbox')))\n",
    "        search_field_designation=driver.find_element(By.ID,value=\"twotabsearchtextbox\")\n",
    "        search_field_designation.send_keys(itemValue)\n",
    "        processorFilter=driver.find_element(By.ID,value=\"nav-search-submit-button\")\n",
    "        driver.execute_script(\"arguments[0].click();\", processorFilter)\n",
    "        time.sleep(2)\n",
    "        urls=[]\n",
    "        price=[]\n",
    "        for page in range(20):\n",
    "            try:\n",
    "                price_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"a-size-base a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]/span[@class=\"a-price\"]/span/span[@class=\"a-price-whole\"]')))\n",
    "                price_data=driver.find_elements(By.XPATH,'//a[@class=\"a-size-base a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]/span[@class=\"a-price\"]/span/span[@class=\"a-price-whole\"]')\n",
    "                product_urls=driver.find_elements(By.XPATH,'//a[@class=\"a-size-base a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "                for m in range(len(product_urls)):\n",
    "                    fullurl=product_urls[m].get_attribute('href')\n",
    "                    if not 'ink' in fullurl.lower():\n",
    "                        urls.append(fullurl)\n",
    "                        price.append(price_data[m].text)\n",
    "                page=page+1\n",
    "                product_page=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')))\n",
    "                product_page=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "                product_page.click()\n",
    "                time.sleep(1)\n",
    "            except TimeoutException as exception:\n",
    "                print(\"Got Exception1\")\n",
    "                continue\n",
    "        list(dict.fromkeys(urls))\n",
    "        df_prod_uls=pd.DataFrame({'URL':urls,'Price':price})\n",
    "        df_prod_uls.to_csv('product_url.csv', mode='a', header=False)\n",
    "        print(len(urls))\n",
    "        all_rating_urls=[]\n",
    "        prod_url=[]\n",
    "        prod_price=[]\n",
    "        for p in range(len(urls)):\n",
    "            driver.get(urls[p])\n",
    "            time.sleep(1)\n",
    "            try:             \n",
    "                full_rating_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"a-link-emphasis a-text-bold\"]')))\n",
    "                full_rating_data=driver.find_element(By.XPATH,'//a[@class=\"a-link-emphasis a-text-bold\"]')\n",
    "                all_rating_url = full_rating_data.get_attribute('href')\n",
    "                all_rating_urls.append(all_rating_url)\n",
    "                prod_url.append(urls[p])\n",
    "                prod_price.append(price[p])\n",
    "            except TimeoutException as exception:\n",
    "                print(\"Got Exception2\")\n",
    "                continue\n",
    "        list(dict.fromkeys(all_rating_urls))\n",
    "        df_rr_uls=pd.DataFrame({'rrURL':all_rating_urls,'prod_url':prod_url,'price':prod_price})\n",
    "        df_rr_uls.to_csv('rr_url.csv', mode='a', header=False)\n",
    "        print(len(df_rr_uls))\n",
    "        for n in range(len(all_rating_urls)):\n",
    "            driver.get(all_rating_urls[n])\n",
    "            time.sleep(1)\n",
    "            for y in range(10):\n",
    "                try:\n",
    "                    rating_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"a-section celwidget\"]/div[@class=\"a-row\"]/a[@class=\"a-link-normal\"]/i[contains(@class,\"a-icon a-icon-star a-star\")]/span[@class=\"a-icon-alt\"]')))\n",
    "                    rating_data=driver.find_elements(By.XPATH,'//div[@class=\"a-section celwidget\"]/div[@class=\"a-row\"]/a[@class=\"a-link-normal\"]/i[contains(@class,\"a-icon a-icon-star a-star\")]/span[@class=\"a-icon-alt\"]')\n",
    "                    review_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"a-section celwidget\"]/div[@class=\"a-row\"]/a[@class=\"a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold\"]/span')))\n",
    "                    review_data=driver.find_elements(By.XPATH,'//div[@class=\"a-section celwidget\"]/div[@class=\"a-row\"]/a[@class=\"a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold\"]/span')\n",
    "                    name_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//h1[@class=\"a-size-large a-text-ellipsis\"]')))\n",
    "                    name_data=driver.find_element(By.XPATH,'//h1[@class=\"a-size-large a-text-ellipsis\"]')\n",
    "                    reviewCount=len(review_data)\n",
    "                    final_price_data=price[n]\n",
    "                    j=0\n",
    "                    review=[]\n",
    "                    rating=[]\n",
    "                    product_name=[]\n",
    "                    brand_name=[]\n",
    "                    product_type=[]\n",
    "                    final_price=[]\n",
    "                    sitename=[]\n",
    "                    for i in range(reviewCount):\n",
    "                        if(review_data[i].text!=''):\n",
    "                            review.append(review_data[i].text)\n",
    "                            rating.append(rating_data[j].get_attribute('innerHTML').split(\" \")[0])\n",
    "                            product_name.append(name_data.text)\n",
    "                            brand_name.append(name_data.text.split(\" \")[0])\n",
    "                            product_type.append(itemValue)\n",
    "                            sitename.append(websitename)\n",
    "                            final_price.append(final_price_data)\n",
    "                            j=j+1\n",
    "                    df=pd.DataFrame({'WebSite':sitename,'Product_type':product_type,'Brand':brand_name,'Product_name':product_name,'Price':final_price,\n",
    "                       'Rating':rating,'Review':review})\n",
    "                    df.to_csv('review_rating_amazon.csv', mode='a', header=False)\n",
    "                except TimeoutException as exception:\n",
    "                    print(\"Got Exception3\")\n",
    "                    continue\n",
    "                try:\n",
    "                    time.sleep(3)\n",
    "                    all_rating_page=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//li[@class=\"a-last\"]')))\n",
    "                    all_rating_page=driver.find_element(By.XPATH,'//li[@class=\"a-last\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\", all_rating_page)\n",
    "                    time.sleep(3)\n",
    "                except TimeoutException as exception:\n",
    "                    print(\"Got Exception4\")\n",
    "                    break\n",
    "\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4849619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siteinfo={\"Amazon\":\"http://www.amazon.in\",\"Flipkart\":\"http://www.flipkart.com\"}\n",
    "#product_info={1:'SmartPhone',2:'Laptop',3:'Headphone',4:'smart watch',5:'Professional Camera',6:'Printer',7:'Home theater',8:'Router'}\n",
    "\n",
    "\n",
    "siteinfo={\"Flipkart\":\"https://www.flipkart.com\"}\n",
    "for websitename,siteurl in siteinfo.items(): \n",
    "    product_info={1:'SmartPhone',2:'Laptop',3:'Headphone',4:'smart watch',5:'Professional Camera',6:'Printer',7:'Home theater',8:'Router'}\n",
    "    for itemKey,itemValue in product_info.items():\n",
    "        driver.get(siteurl)\n",
    "        time.sleep(2)\n",
    "        secs=10\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,value=\"/html/body/div[2]/div/div/button\").click()\n",
    "        except NoSuchElementException:\n",
    "            z=1        \n",
    "        search_field_designation=driver.find_element(By.CLASS_NAME,value='_3704LK')\n",
    "        search_field_designation.send_keys(itemValue)\n",
    "        time.sleep(2)\n",
    "        processorFilter = driver.find_element(By.CLASS_NAME,value='L0Z3Pu')\n",
    "        driver.execute_script(\"arguments[0].click();\", processorFilter)\n",
    "        time.sleep(2)\n",
    "        urls=[]\n",
    "        price=[]\n",
    "        for page in range(19):\n",
    "            product_urls=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"s1Q9rs\"]')))\n",
    "            product_urls=driver.find_elements(By.XPATH,'//a[@class=\"s1Q9rs\"]')\n",
    "            price_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"_30jeq3\"]')))\n",
    "            price_data=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "            for m in range(len(product_urls)):\n",
    "                if 'home theatre' in product_urls[m].text.lower():\n",
    "                    fullurl=product_urls[m].get_attribute('href')\n",
    "                    urls.append(fullurl)\n",
    "                    price.append(price_data[m].text)\n",
    "            page=page+1\n",
    "            nextTag=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"_1LKTO3\"]')))\n",
    "            nextTag=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "            tagcount=len(nextTag)\n",
    "            nextTag[tagcount-1].click()\n",
    "            time.sleep(3)\n",
    "        list(dict.fromkeys(urls)) \n",
    "        print(len(urls))\n",
    "        for n in range(len(urls)):\n",
    "            driver.get(urls[n])  \n",
    "            time.sleep(4)\n",
    "            try:\n",
    "                rating_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//div[starts-with(@class, \"_3LWZlK\") and contains(@class,\"_1BLPMq\")]')))\n",
    "                rating_data=driver.find_elements(By.XPATH,'//div[starts-with(@class, \"_3LWZlK\") and contains(@class,\"_1BLPMq\")]')\n",
    "                review_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//p[@class=\"_2-N8zT\"]')))\n",
    "                review_data=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "                name_data=WebDriverWait(driver, secs).until(EC.presence_of_element_located((By.XPATH,'//span[@class=\"B_NuCI\"]')))\n",
    "                name_data=driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')\n",
    "                reviewCount=len(review_data)\n",
    "                final_price_data=price[n]\n",
    "                review=[]\n",
    "                rating=[]\n",
    "                product_name=[]\n",
    "                brand_name=[]\n",
    "                product_type=[]\n",
    "                final_price=[]\n",
    "                sitename=[]\n",
    "                print(urls[n])\n",
    "                print(reviewCount)\n",
    "                print(len(rating_data))\n",
    "                for i in range(reviewCount):\n",
    "                    if(review_data[i].text!=''):\n",
    "                        review.append(review_data[i].text)\n",
    "                        rating.append(rating_data[i].text)\n",
    "                        product_name.append(name_data.text)\n",
    "                        brand_name.append(name_data.text.split(\" \")[0])\n",
    "                        product_type.append(itemValue)\n",
    "                        sitename.append(websitename)\n",
    "                        final_price.append(final_price_data)\n",
    "                df=pd.DataFrame({'WebSite':sitename,'Product_type':product_type,'Brand':brand_name,'Product_name':product_name,'Price':final_price,\n",
    "                   'Rating':rating,'Review':review})\n",
    "                df\n",
    "                df.to_csv('review_rating_flipkart.csv', mode='a', header=False)\n",
    "            except TimeoutException as exception:\n",
    "                continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97deea4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
